# -*- coding: utf-8 -*-
"""Assessment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L6xkPboik7mL1GUE0l1AfZvQ09kphNNi
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

train_data = pd.read_csv('train_LZdllcl (1).csv')

train_data.head()

train_data.shape

train_data.describe()

train_data.info()

train_data.isna().sum()

train_data['education'].fillna(train_data['education'].mode()[0],inplace = True)

train_data['previous_year_rating'].fillna(train_data['previous_year_rating'].median(), inplace=True)

train_data.isna().sum()

#Feature Selection

X_train = train_data.drop(['employee_id','is_promoted'],axis=1)
y_train = train_data['is_promoted']

X_train.head()

y_train.head()

# Encode the target variable
from sklearn.preprocessing import LabelEncoder
lr=LabelEncoder()
y_train=lr.fit_transform(y_train)

X_train = pd.get_dummies(X_train, columns=X_train.select_dtypes(include=['object', 'category']).columns.tolist(), dtype='int64')
X_train.head()

# Scaling Feature
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_train=sc.fit_transform(X_train)

#Test Data

test_data = pd.read_csv('test_2umaH9m (1).csv')

test_data.head()

test_data.shape

test_data.describe()

test_data.info()

test_data.isna().sum()

test_data['previous_year_rating'] = test_data['previous_year_rating'].fillna(test_data['previous_year_rating'].median())

test_data['education'] = test_data['education'].fillna(test_data['education'].mode()[0])

test_data.isna().sum()

#Feature Selection

X_test = test_data.drop(['employee_id'],axis=1)

X_test.head()

X_test = pd.get_dummies(X_test, columns=X_test.select_dtypes(include=['object', 'category']).columns.tolist(), dtype='int64')
X_test.head()

x = train_data.drop('is_promoted',axis=1)
y = train_data['is_promoted']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.2)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Modeling

from sklearn.metrics import confusion_matrix, accuracy_score

from sklearn.neighbors import KNeighborsClassifier
metric_k = []
neighbors = np.arange(3,15)
for k in neighbors:
  k_model = KNeighborsClassifier(n_neighbors=k,metric='minkowski')
  k_model.fit(X_train,y_train)
  y_pred = k_model.predict(X_test)
  acc = accuracy_score(y_test,y_pred)
  metric_k.append(acc)

plt.plot(neighbors,metric_k,'o-')
plt.xlabel('k value')
plt.ylabel('accuracy')
plt.grid()

k_model = KNeighborsClassifier(n_neighbors=11,metric='minkowski')
k_model.fit(X_train,y_train)
y_pred = k_model.predict(X_test)
acc = accuracy_score(y_test,y_pred)

print(acc)

#Random Forest Clsassifier

from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier()
rf_model.fit(X_train,y_train)
y_pred = rf_model.predict(X_test)
acc = accuracy_score(y_test,y_pred)
print(acc)

# Random forest classifier is best model, which gives high accuracy

sub_file = pd.read_csv('sample_submission_M0L0uXE (1).csv')

sub_file.head()

if len(y_pred) == len(sub_file):
  sub_file['is_promoted'] = y_pred
  sub_file.head()
else:
  print(f"Error: Length of y_pred ({len(y_pred)}) does not match length of sub_file ({len(sub_file)}).")